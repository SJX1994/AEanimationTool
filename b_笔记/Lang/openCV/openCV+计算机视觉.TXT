python：
      Matplotlib:
            安装：
                  pip install matplotlib
            简介：
                  数值数学扩展 NumPy 的绘图 Matplotlib 库
      opencv:
            安装：
                  pip install opencv-python
            简介：
                  主要针对实时计算机视觉的编程函数库。
计算机视觉：
      例子：NVIDIA Canvas

      神经网络：
            灵感来源：神经元在视觉皮层上工作
            关键结论1：大脑皮层上的细胞与视觉中的区域相关联，有映射关系。
            关键结论2：神经元间存在分层关系。
            结构：初级层次的细胞对光的方向产生反应，复杂一点的会对光的移动有反应，超复杂的可以反应端点，识别形状。
            ref：https://www.showmeai.tech/article-detail/264
            常规神经网络：
                  常规神经网络的输入是一个向量，比如把一张 32x32x3 的图片延展成 3072*1 的列向量 公式，然后在一系列的隐层中对它做变换。
                  它输出的值被看做是不同类别的评分值。
                  如：W 是 10 个 3072的权重矩阵，最终输出就是 10 * 1 的 得分向量，每一个值是 W 和每一个3072点乘的结果。3072和每一个神经元相连，因此叫 全连接层
            卷积网络：
                  与常规神经网络不同，卷积神经网络的各层中的神经元都是 3 维的：宽度、高度和深度
                  与输入相连的神经元权重不再是 W 的一个行向量（3072个参数），而是与输入数据有同样深度的滤波器（filter，也称作卷积核），比如是 5x5x3 的滤波器 w。
                  这时的神经元（卷积核）不再与输入图像 x 是全连接的，而是局部连接（local connectivity）,只和 x 中一个 5x5x3 的小区域进行全连接
                  结构：
                        输入层：卷积层：ReLU层:池化层：全连接层：
                        例子：
                              输入层：是 32x32x3 的原始像素，宽高32，有3个颜色通道。
                              卷积层：如果使用12个 滤波器/卷积核 输出数据的维度就是 32x32x12
                              池化层：在宽度和高度上进行降采样（downsampling）假设数据尺寸变成16x16x12
                              全连接:层将会计算分类评分,数据尺寸变成 1x1x10  10 个数字对应的就是 CIFAR-10 中 10 个类别的分类评分值


      CNN架构：
            AlexNet
            VGG
            GoogLeNet
            Inception Module
            ResNet(Residual neural network)残差神经网络:
                  长短期记忆 
                  循环神经网络
概念：            
      迁移学习 (Transfer Learning)：
            机器学习的概念，初衷是节省人工标注样本的时间，让模型可以通过已有的标记数据（source domain data）向未标记数据（target domain data）迁移。
      目标检测(ObjectDetection):
            算法：
                  SSD: Single Shot MultiBox Detector
            机器视觉的中心问题。三个层次分别为：
            分类（Classification）
                  即是将图像结构化为某一类别的信息，用事先确定好的类别(string)或实例ID来描述图片。这一任务是最简单、最基础的图像理解任务，也是深度学习模型最先取得突破和实现大规模应用的任务。在应用领域，人脸、场景的识别等都可以归为分类任务。
            检测（Detection）
                  分类任务关心整体，给出的是整张图片的内容描述，而检测则关注特定的物体目标，要求同时获得这一目标的类别信息和位置信息。检测模型的输出是一个列表，列表的每一项使用一个数据组给出检出目标的类别和位置（常用矩形检测框的坐标表示）。
            分割（Segmentation）
                  分割包括语义分割（semantic segmentation）和实例分割（instance segmentation）。前者是对前背景分离的拓展，要求分离开具有不同语义的图像部分，而后者是检测任务的拓展，要求描述出目标的轮廓（相比检测框更为精细）。分割是对图像的像素级描述，它赋予每个像素类别（实例）意义，适用于理解要求较高的场景，如无人驾驶中对道路和非道路的分割。